{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e508a54",
   "metadata": {},
   "source": [
    "# 1. Load and clean data\n",
    "Run the section below to load and clean the dataset. You do not need to understand the code. The code displays data for the first few chocolates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52151664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Run to load and clean the dataset\n",
    "%reset -f\n",
    "# from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg as nla\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import six\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febb1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output display to have one digit for decimal places and limit it to\n",
    "# printing 15 rows.\n",
    "pd.options.display.max_rows =  15\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2c574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/flavors_of_cacao.csv\", sep=\",\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5e29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns.\n",
    "choc_data.columns = ['maker', 'specific_origin', 'reference_number', 'review_date', 'cocoa_percent', 'maker_location', 'rating', 'bean_type', 'broad_origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfaa419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maker                object\n",
       "specific_origin      object\n",
       "reference_number      int64\n",
       "review_date           int64\n",
       "cocoa_percent        object\n",
       "maker_location       object\n",
       "rating              float64\n",
       "bean_type            object\n",
       "broad_origin         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52188d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   maker             1795 non-null   object \n",
      " 1   specific_origin   1795 non-null   object \n",
      " 2   reference_number  1795 non-null   int64  \n",
      " 3   review_date       1795 non-null   int64  \n",
      " 4   cocoa_percent     1795 non-null   object \n",
      " 5   maker_location    1795 non-null   object \n",
      " 6   rating            1795 non-null   float64\n",
      " 7   bean_type         907 non-null    object \n",
      " 8   broad_origin      1721 non-null   object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 126.3+ KB\n"
     ]
    }
   ],
   "source": [
    "choc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896caf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty/null values with \"Blend\"\n",
    "choc_data['bean_type'] = choc_data['bean_type'].fillna('Blend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ef7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast bean_type to string to remove leading 'u'\n",
    "choc_data['bean_type'] = choc_data['bean_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c15940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data['cocoa_percent'] = choc_data['cocoa_percent'].str.strip('%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c26634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data['cocoa_percent'] = pd.to_numeric(choc_data['cocoa_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5980c1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   maker             1795 non-null   object \n",
      " 1   specific_origin   1795 non-null   object \n",
      " 2   reference_number  1795 non-null   int64  \n",
      " 3   review_date       1795 non-null   int64  \n",
      " 4   cocoa_percent     1795 non-null   float64\n",
      " 5   maker_location    1795 non-null   object \n",
      " 6   rating            1795 non-null   float64\n",
      " 7   bean_type         1795 non-null   object \n",
      " 8   broad_origin      1721 non-null   object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 126.3+ KB\n"
     ]
    }
   ],
   "source": [
    "choc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "general-lesson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Cibao Valley, Domin. Rep.</td>\n",
       "      <td>1061</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Domin. Rep.</td>\n",
       "      <td>1069</td>\n",
       "      <td>2013</td>\n",
       "      <td>82.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Domin. Rep.</td>\n",
       "      <td>1069</td>\n",
       "      <td>2013</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Domin. Rep.</td>\n",
       "      <td>1073</td>\n",
       "      <td>2013</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Xocolat</td>\n",
       "      <td>Hispaniola</td>\n",
       "      <td>1057</td>\n",
       "      <td>2013</td>\n",
       "      <td>66.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        maker                         specific_origin  reference_number  \\\n",
       "883   Kah Kow  Rizek Cacao, Cibao Valley, Domin. Rep.              1061   \n",
       "884   Kah Kow                Rizek Cacao, Domin. Rep.              1069   \n",
       "885   Kah Kow                Rizek Cacao, Domin. Rep.              1069   \n",
       "886   Kah Kow                Rizek Cacao, Domin. Rep.              1073   \n",
       "1758  Xocolat                              Hispaniola              1057   \n",
       "\n",
       "      review_date  cocoa_percent     maker_location  rating bean_type  \\\n",
       "883          2013          70.00  Domincan Republic    3.50     Blend   \n",
       "884          2013          82.00  Domincan Republic    3.00     Blend   \n",
       "885          2013          55.00  Domincan Republic    3.25     Blend   \n",
       "886          2013          62.00  Domincan Republic    3.25     Blend   \n",
       "1758         2013          66.00  Domincan Republic    3.00     Blend   \n",
       "\n",
       "            broad_origin  \n",
       "883   Dominican Republic  \n",
       "884   Dominican Republic  \n",
       "885   Dominican Republic  \n",
       "886   Dominican Republic  \n",
       "1758  Dominican Republic  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['maker_location'].isin(['Domincan Republic'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coastal-baking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Trinidad, Heritage, Limited ed.</td>\n",
       "      <td>1193</td>\n",
       "      <td>2013</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Trinidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Colombia, Casa Luker</td>\n",
       "      <td>947</td>\n",
       "      <td>2012</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>729</td>\n",
       "      <td>2011</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Haiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Panama</td>\n",
       "      <td>745</td>\n",
       "      <td>2011</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Panama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>486</td>\n",
       "      <td>2010</td>\n",
       "      <td>100.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>Hacienda Las Trincheras</td>\n",
       "      <td>593</td>\n",
       "      <td>2010</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>Java</td>\n",
       "      <td>593</td>\n",
       "      <td>2010</td>\n",
       "      <td>69.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>San Martin</td>\n",
       "      <td>457</td>\n",
       "      <td>2009</td>\n",
       "      <td>70.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>Rio Caribe</td>\n",
       "      <td>457</td>\n",
       "      <td>2009</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Xocolat</td>\n",
       "      <td>Hispaniola</td>\n",
       "      <td>1057</td>\n",
       "      <td>2013</td>\n",
       "      <td>66.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    maker                  specific_origin  reference_number  \\\n",
       "121   Artisan du Chocolat  Trinidad, Heritage, Limited ed.              1193   \n",
       "122   Artisan du Chocolat             Colombia, Casa Luker               947   \n",
       "123   Artisan du Chocolat                            Haiti               729   \n",
       "124   Artisan du Chocolat                           Panama               745   \n",
       "125   Artisan du Chocolat                        Venezuela               486   \n",
       "...                   ...                              ...               ...   \n",
       "1743       Willie's Cacao          Hacienda Las Trincheras               593   \n",
       "1744       Willie's Cacao                             Java               593   \n",
       "1745       Willie's Cacao                       San Martin               457   \n",
       "1746       Willie's Cacao                       Rio Caribe               457   \n",
       "1758              Xocolat                       Hispaniola              1057   \n",
       "\n",
       "      review_date  cocoa_percent     maker_location  rating   bean_type  \\\n",
       "121          2013          72.00               U.K.    3.25  Trinitario   \n",
       "122          2012          72.00               U.K.    3.75       Blend   \n",
       "123          2011          72.00               U.K.    4.00       Blend   \n",
       "124          2011          72.00               U.K.    2.75       Blend   \n",
       "125          2010         100.00               U.K.    1.75       Blend   \n",
       "...           ...            ...                ...     ...         ...   \n",
       "1743         2010          72.00               U.K.    3.50       Blend   \n",
       "1744         2010          69.00               U.K.    3.75       Blend   \n",
       "1745         2009          70.00               U.K.    3.00       Blend   \n",
       "1746         2009          72.00               U.K.    3.25  Trinitario   \n",
       "1758         2013          66.00  Domincan Republic    3.00       Blend   \n",
       "\n",
       "            broad_origin  \n",
       "121             Trinidad  \n",
       "122             Colombia  \n",
       "123                Haiti  \n",
       "124               Panama  \n",
       "125            Venezuela  \n",
       "...                  ...  \n",
       "1743           Venezuela  \n",
       "1744           Indonesia  \n",
       "1745                Peru  \n",
       "1746           Venezuela  \n",
       "1758  Dominican Republic  \n",
       "\n",
       "[106 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['maker_location'].isin(['Domincan Republic','Amsterdam', 'U.K.', 'Niacragua'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76143337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling mistakes, and replace city with country name\n",
    "choc_data['maker_location'] = choc_data['maker_location']\\\n",
    ".str.replace('Amsterdam', 'Holland', regex=True)\\\n",
    ".str.replace('U.K.', 'England', regex=True)\\\n",
    ".str.replace('Niacragua', 'Nicaragua', regex=True)\\\n",
    ".str.replace('Domincan Republic', 'Dominican Republic', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aquatic-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding this so that Holland and Netherlands map to the same country.\n",
    "choc_data['maker_location'] = choc_data['maker_location']\\\n",
    ".str.replace('Holland', 'Netherlands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "single-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_spelling_abbrev(text):\n",
    "    replacements = [\n",
    "        ['-', ', '], ['/ ', ', '], ['/', ', '], ['\\(', ', '], [' and', ', '], [' &', ', '], ['\\)', ''],\n",
    "        ['Dom Rep|DR|Domin Rep|Dominican Rep,|Domincan Republic', 'Dominican Republic'],\n",
    "        ['Mad,|Mad$', 'Madagascar, '],\n",
    "        ['PNG', 'Papua New Guinea, '],\n",
    "        ['Guat,|Guat$', 'Guatemala, '],\n",
    "        ['Ven,|Ven$|Venez,|Venez$', 'Venezuela, '],\n",
    "        ['Ecu,|Ecu$|Ecuad,|Ecuad$', 'Ecuador, '],\n",
    "        ['Nic,|Nic$', 'Nicaragua, '],\n",
    "        ['Cost Rica', 'Costa Rica'],\n",
    "        ['Mex,|Mex$', 'Mexico, '],\n",
    "        ['Jam,|Jam$', 'Jamaica, '],\n",
    "        ['Haw,|Haw$', 'Hawaii, '],\n",
    "        ['Gre,|Gre$', 'Grenada, '],\n",
    "        ['Tri,|Tri$', 'Trinidad, '],\n",
    "        ['C Am', 'Central America'],\n",
    "        ['S America', 'South America'],\n",
    "        [', $', ''], [',  ', ', '], [', ,', ', '], ['\\xa0', ' '],[',\\s+', ','],\n",
    "        [' Bali', ',Bali']\n",
    "    ]\n",
    "    for i, j in replacements:\n",
    "        text = re.sub(i, j, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decimal-guarantee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Akesson's (Pralus)</td>\n",
       "      <td>Madagascar, Ambolikapiky P.</td>\n",
       "      <td>502</td>\n",
       "      <td>2010</td>\n",
       "      <td>75.00</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Criollo</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Akesson's (Pralus)</td>\n",
       "      <td>Monte Alegre, D. Badero</td>\n",
       "      <td>508</td>\n",
       "      <td>2010</td>\n",
       "      <td>75.00</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>AMMA</td>\n",
       "      <td>Monte Alegre, 3 diff. plantations</td>\n",
       "      <td>572</td>\n",
       "      <td>2010</td>\n",
       "      <td>85.00</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Forastero (Parazinho)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>AMMA</td>\n",
       "      <td>Monte Alegre, 3 diff. plantations</td>\n",
       "      <td>572</td>\n",
       "      <td>2010</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Forastero (Parazinho)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>AMMA</td>\n",
       "      <td>Monte Alegre, 3 diff. plantations</td>\n",
       "      <td>572</td>\n",
       "      <td>2010</td>\n",
       "      <td>75.00</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Forastero (Parazinho)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Valrhona</td>\n",
       "      <td>Sambirano, Ampamakia 2005, Millot P.</td>\n",
       "      <td>75</td>\n",
       "      <td>2006</td>\n",
       "      <td>64.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Wm</td>\n",
       "      <td>Guasare, Zulia Prov., 2015, batch 124</td>\n",
       "      <td>1912</td>\n",
       "      <td>2016</td>\n",
       "      <td>74.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Criollo</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Woodblock</td>\n",
       "      <td>Camino Verde P., Balao, Guayas</td>\n",
       "      <td>1042</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Ecuador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Zart Pralinen</td>\n",
       "      <td>Millot P., Ambanja</td>\n",
       "      <td>1820</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Criollo, Trinitario</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Loma Los Pinos, Yacao region, D.R.</td>\n",
       "      <td>875</td>\n",
       "      <td>2012</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   maker                        specific_origin  \\\n",
       "33    Akesson's (Pralus)            Madagascar, Ambolikapiky P.   \n",
       "34    Akesson's (Pralus)                Monte Alegre, D. Badero   \n",
       "89                  AMMA      Monte Alegre, 3 diff. plantations   \n",
       "90                  AMMA      Monte Alegre, 3 diff. plantations   \n",
       "91                  AMMA      Monte Alegre, 3 diff. plantations   \n",
       "...                  ...                                    ...   \n",
       "1702            Valrhona   Sambirano, Ampamakia 2005, Millot P.   \n",
       "1747                  Wm  Guasare, Zulia Prov., 2015, batch 124   \n",
       "1751           Woodblock         Camino Verde P., Balao, Guayas   \n",
       "1767       Zart Pralinen                     Millot P., Ambanja   \n",
       "1783              Zotter     Loma Los Pinos, Yacao region, D.R.   \n",
       "\n",
       "      reference_number  review_date  cocoa_percent maker_location  rating  \\\n",
       "33                 502         2010          75.00    Switzerland    2.75   \n",
       "34                 508         2010          75.00    Switzerland    2.75   \n",
       "89                 572         2010          85.00         Brazil    2.75   \n",
       "90                 572         2010          50.00         Brazil    3.75   \n",
       "91                 572         2010          75.00         Brazil    3.75   \n",
       "...                ...          ...            ...            ...     ...   \n",
       "1702                75         2006          64.00         France    3.50   \n",
       "1747              1912         2016          74.00         U.S.A.    3.00   \n",
       "1751              1042         2013          70.00         U.S.A.    3.25   \n",
       "1767              1820         2016          70.00        Austria    3.50   \n",
       "1783               875         2012          62.00        Austria    3.75   \n",
       "\n",
       "                  bean_type        broad_origin  \n",
       "33                  Criollo          Madagascar  \n",
       "34                Forastero              Brazil  \n",
       "89    Forastero (Parazinho)              Brazil  \n",
       "90    Forastero (Parazinho)              Brazil  \n",
       "91    Forastero (Parazinho)              Brazil  \n",
       "...                     ...                 ...  \n",
       "1702             Trinitario          Madagascar  \n",
       "1747                Criollo           Venezuela  \n",
       "1751                  Blend             Ecuador  \n",
       "1767    Criollo, Trinitario          Madagascar  \n",
       "1783                  Blend  Dominican Republic  \n",
       "\n",
       "[156 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['specific_origin'].str.contains('\\.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "understanding-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data['specific_origin'] = choc_data['specific_origin']\\\n",
    ".str.replace('\\.', '', regex=True).apply(cleanup_spelling_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ongoing-confidentiality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loma Los Pinos,Yacao region,Dominican Republic'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data['specific_origin'][1783]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "trying-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   maker             1795 non-null   object \n",
      " 1   specific_origin   1795 non-null   object \n",
      " 2   reference_number  1795 non-null   int64  \n",
      " 3   review_date       1795 non-null   int64  \n",
      " 4   cocoa_percent     1795 non-null   float64\n",
      " 5   maker_location    1795 non-null   object \n",
      " 6   rating            1795 non-null   float64\n",
      " 7   bean_type         1795 non-null   object \n",
      " 8   broad_origin      1721 non-null   object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 126.3+ KB\n"
     ]
    }
   ],
   "source": [
    "choc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ethical-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast specific_origin to string\n",
    "choc_data['specific_origin'] = choc_data['specific_origin'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "maritime-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null-valued fields with the same value as for specific_origin\n",
    "choc_data['broad_origin'] = choc_data['broad_origin'].fillna(choc_data['specific_origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "medical-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up spelling mistakes and deal with abbreviations\n",
    "choc_data['broad_origin'] = choc_data['broad_origin'].str.replace('\\.', '', regex=True).apply(cleanup_spelling_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "minor-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Cacao Barry</td>\n",
       "      <td>Grand 'Anse</td>\n",
       "      <td>1716</td>\n",
       "      <td>2016</td>\n",
       "      <td>65.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Haiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>Felchlin</td>\n",
       "      <td>Elvesia P</td>\n",
       "      <td>105</td>\n",
       "      <td>2006</td>\n",
       "      <td>74.00</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>Guittard</td>\n",
       "      <td>Sur del Lago</td>\n",
       "      <td>87</td>\n",
       "      <td>2006</td>\n",
       "      <td>65.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Hotel Chocolat (Coppeneur)</td>\n",
       "      <td>Sambirano</td>\n",
       "      <td>809</td>\n",
       "      <td>2012</td>\n",
       "      <td>66.00</td>\n",
       "      <td>England</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>Hummingbird</td>\n",
       "      <td>Ocumare,Cumboto</td>\n",
       "      <td>1097</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>La Chocolaterie Nanairo</td>\n",
       "      <td>Lumas,2015 Harvest,Batch 6,brown sugar</td>\n",
       "      <td>1892</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2.25</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>La Chocolaterie Nanairo</td>\n",
       "      <td>Lumas,2015 Harvest,Batch 7</td>\n",
       "      <td>1892</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>La Chocolaterie Nanairo</td>\n",
       "      <td>Belize,2014 Harvest,Batch 9</td>\n",
       "      <td>1892</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Belize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>Scharffen Berger</td>\n",
       "      <td>Amina</td>\n",
       "      <td>464</td>\n",
       "      <td>2010</td>\n",
       "      <td>65.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           maker                         specific_origin  \\\n",
       "284                  Cacao Barry                             Grand 'Anse   \n",
       "645                     Felchlin                               Elvesia P   \n",
       "766                     Guittard                            Sur del Lago   \n",
       "837   Hotel Chocolat (Coppeneur)                               Sambirano   \n",
       "854                  Hummingbird                         Ocumare,Cumboto   \n",
       "926      La Chocolaterie Nanairo  Lumas,2015 Harvest,Batch 6,brown sugar   \n",
       "927      La Chocolaterie Nanairo              Lumas,2015 Harvest,Batch 7   \n",
       "929      La Chocolaterie Nanairo             Belize,2014 Harvest,Batch 9   \n",
       "1430            Scharffen Berger                                   Amina   \n",
       "\n",
       "      reference_number  review_date  cocoa_percent maker_location  rating  \\\n",
       "284               1716         2016          65.00         France    3.50   \n",
       "645                105         2006          74.00    Switzerland    3.00   \n",
       "766                 87         2006          65.00         U.S.A.    2.50   \n",
       "837                809         2012          66.00        England    3.50   \n",
       "854               1097         2013          70.00         Canada    3.25   \n",
       "926               1892         2016          70.00          Japan    2.25   \n",
       "927               1892         2016          70.00          Japan    2.50   \n",
       "929               1892         2016          70.00          Japan    3.00   \n",
       "1430               464         2010          65.00         U.S.A.    3.75   \n",
       "\n",
       "                bean_type        broad_origin  \n",
       "284   Trinitario, Criollo               Haiti  \n",
       "645   Trinitario, Criollo  Dominican Republic  \n",
       "766   Trinitario, Criollo           Venezuela  \n",
       "837   Trinitario, Criollo          Madagascar  \n",
       "854   Trinitario, Criollo           Venezuela  \n",
       "926   Trinitario, Criollo                Peru  \n",
       "927   Trinitario, Criollo                Peru  \n",
       "929   Trinitario, Criollo              Belize  \n",
       "1430  Trinitario, Criollo          Madagascar  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['bean_type'].isin(['Trinitario, Criollo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "heated-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blend', 'Criollo', 'Trinitario', 'Forastero (Arriba)',\n",
       "       'Forastero', 'Forastero (Nacional)', 'Criollo, Trinitario',\n",
       "       'Criollo (Porcelana)', 'Trinitario (85% Criollo)',\n",
       "       'Forastero (Catongo)', 'Forastero (Parazinho)',\n",
       "       'Trinitario, Criollo', 'CCN51', 'Criollo (Ocumare)', 'Nacional',\n",
       "       'Criollo (Ocumare 61)', 'Criollo (Ocumare 77)',\n",
       "       'Criollo (Ocumare 67)', 'Criollo (Wild)', 'Beniano', 'Amazon mix',\n",
       "       'Trinitario, Forastero', 'Forastero (Arriba) ASS', 'Criollo, +',\n",
       "       'Amazon', 'Amazon, ICS', 'EET', 'Blend-Forastero,Criollo',\n",
       "       'Trinitario (Scavina)', 'Criollo, Forastero', 'Matina',\n",
       "       'Forastero(Arriba, CCN)', 'Nacional (Arriba)',\n",
       "       'Forastero (Arriba) ASSS', 'Forastero, Trinitario',\n",
       "       'Forastero (Amelonado)', 'Trinitario, Nacional',\n",
       "       'Trinitario (Amelonado)', 'Trinitario, TCGA', 'Criollo (Amarru)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data['bean_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "talented-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blend                   929\n",
       "Trinitario              419\n",
       "Criollo                 153\n",
       "Forastero                87\n",
       "Forastero (Nacional)     52\n",
       "                       ... \n",
       "Criollo (Ocumare)         1\n",
       "Amazon                    1\n",
       "Criollo, +                1\n",
       "Criollo (Ocumare 77)      1\n",
       "CCN51                     1\n",
       "Name: bean_type, Length: 40, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data['bean_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "configured-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Trinitario, Criollo' to \"Criollo, Trinitario\"\n",
    "# Check with choc_data['bean_type'].unique()\n",
    "choc_data.loc[choc_data['bean_type'].isin(['Trinitario, Criollo']),'bean_type'] = \"Criollo, Trinitario\"\n",
    "# Confirm with choc_data[choc_data['bean_type'].isin(['Trinitario, Criollo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "mathematical-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>Naive</td>\n",
       "      <td>Trinidad,Tobago</td>\n",
       "      <td>1046</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Trinidad,Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>Naive</td>\n",
       "      <td>Maranon Canyon,Fortunato No 4</td>\n",
       "      <td>1133</td>\n",
       "      <td>2013</td>\n",
       "      <td>78.00</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Forastero (Nacional)</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>Naive</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>867</td>\n",
       "      <td>2012</td>\n",
       "      <td>71.00</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Grenada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker                specific_origin  reference_number  review_date  \\\n",
       "1162  Naive                Trinidad,Tobago              1046         2013   \n",
       "1163  Naive  Maranon Canyon,Fortunato No 4              1133         2013   \n",
       "1164  Naive                        Grenada               867         2012   \n",
       "\n",
       "      cocoa_percent maker_location  rating             bean_type  \\\n",
       "1162          70.00      Lithuania    3.75                 Blend   \n",
       "1163          78.00      Lithuania    3.75  Forastero (Nacional)   \n",
       "1164          71.00      Lithuania    2.50            Trinitario   \n",
       "\n",
       "         broad_origin  \n",
       "1162  Trinidad,Tobago  \n",
       "1163             Peru  \n",
       "1164          Grenada  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['maker'].str.contains(r'Na\\w*ve')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "concerned-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix chocolate maker names\n",
    "choc_data.loc[choc_data['maker']=='Shattel','maker'] = 'Shattell'\n",
    "choc_data['maker'] = choc_data['maker'].str.replace(u'Na\\xef\\xbf\\xbdve','Naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-governor",
   "metadata": {},
   "source": [
    "The u in <span style='color:red'>u'Some String'</span> means that your string is a <span style='color:red'>Unicode string</span>.\n",
    "<span style='color:blue'>In Python 3.x the strings use Unicode by default</span> and there's no need for the u prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "superb-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker specific_origin  reference_number  review_date  cocoa_percent  \\\n",
       "0  A. Morin     Agua Grande              1876         2016          63.00   \n",
       "1  A. Morin           Kpime              1676         2015          70.00   \n",
       "2  A. Morin          Atsane              1676         2015          70.00   \n",
       "3  A. Morin           Akata              1680         2015          70.00   \n",
       "4  A. Morin          Quilla              1704         2015          70.00   \n",
       "\n",
       "  maker_location  rating bean_type broad_origin  \n",
       "0         France    3.75     Blend     Sao Tome  \n",
       "1         France    2.75     Blend         Togo  \n",
       "2         France    3.00     Blend         Togo  \n",
       "3         France    3.50     Blend         Togo  \n",
       "4         France    3.50     Blend         Peru  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-calculation",
   "metadata": {},
   "source": [
    "# 2. Process Data\n",
    "Because you're using a DNN, you do not need to manually process the data. The DNN transforms the data for us. However, if possible, you should remove features that could distort the similarity calculation. Here, the features `review_date` and `reference_number` are not correlated with similarity. That is, chocolates that are reviewed closer together in time are not more or less similar than chocolates reviewed further apart. Remove these two features by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "generic-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker specific_origin  cocoa_percent maker_location  rating bean_type  \\\n",
       "0  A. Morin     Agua Grande          63.00         France    3.75     Blend   \n",
       "1  A. Morin           Kpime          70.00         France    2.75     Blend   \n",
       "2  A. Morin          Atsane          70.00         France    3.00     Blend   \n",
       "3  A. Morin           Akata          70.00         France    3.50     Blend   \n",
       "4  A. Morin          Quilla          70.00         France    3.50     Blend   \n",
       "\n",
       "  broad_origin  \n",
       "0     Sao Tome  \n",
       "1         Togo  \n",
       "2         Togo  \n",
       "3         Togo  \n",
       "4         Peru  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data.drop(columns=['review_date','reference_number'],inplace=True)\n",
    "choc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-forward",
   "metadata": {},
   "source": [
    "# 3. Generate Embeddings from DNN\n",
    "\n",
    "We're ready to generate embeddings by training the DNN on the feature data. This section draws on concepts discussed on the page [Supervised Similarity Measure](https://developers.google.com/machine-learning/clustering/similarity/supervised-similarity).\n",
    "\n",
    "Run the section below to set up functions to train the DNN that generates embeddings. You do not need to understand the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-monkey",
   "metadata": {},
   "source": [
    "### Functions to Build and Train a Similarity DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "proprietary-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityModel(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dataframe,\n",
    "                 input_feature_names,\n",
    "                 output_feature_names,\n",
    "                 dense_feature_names,\n",
    "                 sparse_input_feature_embedding_dims,\n",
    "                 hidden_dims=[32],\n",
    "                 l2_regularization=0.0,\n",
    "                 use_bias=True,\n",
    "                 batch_size=100,\n",
    "                 inspect=False):\n",
    "        used_feature_names = tuple(\n",
    "            set(input_feature_names).union(output_feature_names))\n",
    "        sparse_feature_names = tuple(\n",
    "            set(used_feature_names).difference(dense_feature_names))\n",
    "        # Dictionary mapping each sparse feature column to its vocabulary.\n",
    "        ### sparse_feature_vocabs = { 'maker': [u'A. Morin', u'AMMA', ...], ... }\n",
    "        sparse_feature_vocabs = {\n",
    "            sfn: sorted(list(set(choc_data[sfn].values)))\n",
    "            for sfn in sparse_feature_names\n",
    "        }\n",
    "        \n",
    "        # Sparse output features are mapped to ids via tf.feature_to_id, hence\n",
    "        # we need key-id pairs for these vocabularies.\n",
    "        sparse_output_feature_names = (\n",
    "            tuple(set(sparse_feature_names).intersection(output_feature_names)))\n",
    "        keys_and_values = {}\n",
    "        for fn in sparse_output_feature_names:\n",
    "            keys = tf.constant(\n",
    "                sparse_feature_vocabs[fn],\n",
    "                dtype=tf.string,\n",
    "                name='{}_vocab_keys'.format(fn))\n",
    "            values = tf.range(\n",
    "                len(sparse_feature_vocabs[fn]),\n",
    "                dtype=tf.int64,\n",
    "                name='{}_vocab_values'.format(fn))\n",
    "            keys_and_values[fn] = (keys, values)\n",
    "            \n",
    "        # Class instance data members.\n",
    "        self._session = None\n",
    "        self._loss = None\n",
    "        self._metrics = {}\n",
    "        self._embeddings = None\n",
    "        self._vars_to_inspect = {}\n",
    "\n",
    "        def split_dataframe(df, holdout_fraction=0.1):\n",
    "            \n",
    "            test = df.sample(frac=holdout_fraction, replace=False)\n",
    "            train = df[~df.index.isin(test.index)]\n",
    "            return train, test\n",
    "\n",
    "        train_dataframe, test_dataframe = split_dataframe(dataframe)\n",
    "\n",
    "        def make_batch(dataframe, batch_size):\n",
    "            used_features = {ufn: dataframe[ufn] for ufn in used_feature_names}\n",
    "            batch = (\n",
    "                tf.data.Dataset.from_tensor_slices(used_features).shuffle(1000)\n",
    "                .repeat().batch(batch_size).make_one_shot_iterator().get_next())\n",
    "            if inspect:\n",
    "                for k, v in six.iteritems(batch):\n",
    "                    self._vars_to_inspect['input_%s' % k] = v\n",
    "            return batch\n",
    "        \n",
    "        def generate_feature_columns(feature_names):\n",
    "            used_sparse_feature_names = (\n",
    "                tuple(set(sparse_feature_names).intersection(feature_names)))\n",
    "            used_dense_feature_names = (\n",
    "                tuple(set(dense_feature_names).intersection(feature_names)))\n",
    "            f_columns = {}\n",
    "            for sfn in used_sparse_feature_names:\n",
    "                sf_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                    key=sfn,\n",
    "                    vocabulary_list=sparse_feature_vocabs[sfn],\n",
    "                    num_oov_buckets=0)\n",
    "                f_columns[sfn] = tf.feature_column.embedding_column(\n",
    "                    categorical_column=sf_column,\n",
    "                    dimension=sparse_input_feature_embedding_dims[sfn],\n",
    "                    combiner='mean',\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=.1))\n",
    "            for dfn in used_dense_feature_names:\n",
    "                f_columns[dfn] = tf.feature_column.numeric_column(dfn)\n",
    "            return f_columns\n",
    "        \n",
    "        def create_tower(features, columns):\n",
    "            input_columns = [columns[fn] for fn in input_feature_names]\n",
    "            hidden_layer = tf.feature_column.input_layer(features, input_columns)\n",
    "            dense_input_feature_names = (\n",
    "                tuple(set(dense_feature_names).intersection(input_feature_names)))\n",
    "            input_dim = (\n",
    "                sum(sparse_input_feature_embedding_dims.values()) +\n",
    "                len(dense_input_feature_names))\n",
    "            for layer_idx, layer_output_dim in enumerate(hidden_dims):\n",
    "                w = tf.get_variable(\n",
    "                    'hidden%d_w_' % layer_idx,\n",
    "                    shape=[input_dim, layer_output_dim],\n",
    "                    initializer=tf.truncated_normal_initializer(\n",
    "                        stddev=1.0 / np.sqrt(layer_output_dim)))\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['hidden%d_w_' % layer_idx] = w\n",
    "                hidden_layer = tf.matmul(hidden_layer, w)  # / 10.)\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['hidden_layer_%d' % layer_idx] = hidden_layer\n",
    "                input_dim = layer_output_dim\n",
    "              # Output features.\n",
    "            output_layer = {}\n",
    "            for ofn in output_feature_names:\n",
    "                if ofn in sparse_feature_names:\n",
    "                    feature_dim = len(sparse_feature_vocabs[ofn])\n",
    "                else:\n",
    "                    feature_dim = 1\n",
    "                w = tf.get_variable(\n",
    "                    'output_w_%s' % ofn,\n",
    "                    shape=[input_dim, feature_dim],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=1.0 /\n",
    "                                                                np.sqrt(feature_dim)))\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['output_w_%s' % ofn] = w\n",
    "                if use_bias:\n",
    "                    bias = tf.get_variable(\n",
    "                        'output_bias_%s' % ofn,\n",
    "                        shape=[1, feature_dim],\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=1.0 /\n",
    "                                                                    np.sqrt(feature_dim)))\n",
    "                    if inspect:\n",
    "                        self._vars_to_inspect['output_bias_%s' % ofn] = bias\n",
    "                else:\n",
    "                    bias = tf.constant(0.0, shape=[1, feature_dim])\n",
    "                output_layer[ofn] = {\n",
    "                    'labels':\n",
    "                        features[ofn],\n",
    "                    'logits':\n",
    "                        tf.add(tf.matmul(hidden_layer, w), bias)  # w / 10.), bias)\n",
    "                }\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['output_labels_%s' %\n",
    "                                        ofn] = output_layer[ofn]['labels']\n",
    "                    self._vars_to_inspect['output_logits_%s' %\n",
    "                                        ofn] = output_layer[ofn]['logits']\n",
    "                return hidden_layer, output_layer\n",
    "            \n",
    "        def similarity_loss(top_embeddings, output_layer):\n",
    "            \n",
    "            losses = {}\n",
    "            total_loss = tf.scalar_mul(l2_regularization,\n",
    "                                        tf.nn.l2_loss(top_embeddings))\n",
    "            for fn, output in six.iteritems(output_layer):\n",
    "                if fn in sparse_feature_names:\n",
    "                    losses[fn] = tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits=output['logits'],\n",
    "                            labels=tf.feature_to_id(\n",
    "                                output['labels'], keys_and_values=keys_and_values[fn])))\n",
    "                else:\n",
    "                    losses[fn] = tf.sqrt(\n",
    "                        tf.reduce_mean(\n",
    "                            tf.square(output['logits'] -\n",
    "                                    tf.cast(output['labels'], tf.float32))))\n",
    "                total_loss += losses[fn]\n",
    "                return total_loss, losses\n",
    "\n",
    "        # Body of the constructor.\n",
    "        input_feature_columns = generate_feature_columns(input_feature_names)\n",
    "        # Train\n",
    "        with tf.variable_scope('model', reuse=False):\n",
    "            train_hidden_layer, train_output_layer = create_tower(\n",
    "                make_batch(train_dataframe, batch_size), input_feature_columns)\n",
    "            self._train_loss, train_losses = similarity_loss(train_hidden_layer,\n",
    "                                                            train_output_layer)\n",
    "        # Test\n",
    "        with tf.variable_scope('model', reuse=True):\n",
    "            test_hidden_layer, test_output_layer = create_tower(\n",
    "                make_batch(test_dataframe, batch_size), input_feature_columns)\n",
    "            test_loss, test_losses = similarity_loss(test_hidden_layer,\n",
    "                                                    test_output_layer)\n",
    "        # Whole dataframe to get final embeddings\n",
    "        with tf.variable_scope('model', reuse=True):\n",
    "            self._hidden_layer, _ = create_tower(\n",
    "                make_batch(dataframe, dataframe.shape[0]), input_feature_columns)\n",
    "        # Metrics is a dictionary of dictionaries of dictionaries.\n",
    "        # The 3 levels are used as plots, line colors, and line styles respectively.\n",
    "        self._metrics = {\n",
    "            'total': {\n",
    "                'train': {'loss': self._train_loss},\n",
    "                'test': {'loss': test_loss}\n",
    "                },\n",
    "            'feature': {\n",
    "                'train': {'%s loss' % k: v for k, v in six.iteritems(train_losses)},\n",
    "                'test': {'%s loss' % k: v for k, v in six.iteritems(test_losses)}\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        def train(self,\n",
    "                  num_iterations=30,\n",
    "                  learning_rate=1.0,\n",
    "                  plot_results=True,\n",
    "                  optimizer=tf.train.GradientDescentOptimizer):\n",
    "            \n",
    "            with self._train_loss.graph.as_default():\n",
    "                opt = optimizer(learning_rate)\n",
    "                train_op = opt.minimize(self._train_loss)\n",
    "                opt_init_op = tf.variables_initializer(opt.variables())\n",
    "                if self._session is None:\n",
    "                    self._session = tf.Session()\n",
    "                    with self._session.as_default():\n",
    "                        self._session.run(tf.global_variables_initializer())\n",
    "                        self._session.run(tf.local_variables_initializer())\n",
    "                        self._session.run(tf.tables_initializer())\n",
    "                        tf.train.start_queue_runners()\n",
    "                        \n",
    "            with self._session.as_default():\n",
    "                self._session.run(opt_init_op)\n",
    "                if plot_results:  \n",
    "                    iterations = []\n",
    "                    metrics_vals = {k0: {k1: {k2: []\n",
    "                                              for k2 in v1}\n",
    "                                         for k1, v1 in six.iteritems(v0)}\n",
    "                                    for k0, v0 in six.iteritems(self._metrics)}\n",
    "                    \n",
    "                for i in range(num_iterations + 1):\n",
    "                    _, results = self._session.run((train_op, self._metrics))\n",
    "\n",
    "                    if (i % 10 == 0) or i == num_iterations:\n",
    "                        print('\\riteration%6d,   ' % i + ',   '.join(\n",
    "                            ['%s %s %s: %7.3f' % (k0, k1, k2, v2)\n",
    "                            for k0, v0 in six.iteritems(results)\n",
    "                            for k1, v1 in six.iteritems(v0)\n",
    "                            for k2, v2 in six.iteritems(v1)])\n",
    "                            , end=\" \"\n",
    "                            )\n",
    "                        if plot_results:\n",
    "                            iterations.append(i)\n",
    "                            for k0, v0 in six.iteritems(results):\n",
    "                                for k1, v1 in six.iteritems(v0):\n",
    "                                    for k2, v2 in six.iteritems(v1):\n",
    "                                        metrics_vals[k0][k1][k2].append(results[k0][k1][k2])\n",
    "\n",
    "                # Feedforward the entire dataframe to get all the embeddings.\n",
    "                self._embeddings = self._session.run(self._hidden_layer)\n",
    "\n",
    "                # Plot the losses and embeddings.\n",
    "                if plot_results:\n",
    "                    num_subplots = len(metrics_vals) + 1\n",
    "                    colors = 10 * ('red', 'blue', 'black', 'green')\n",
    "                    styles = 10 * ('-', '--', '-.', ':')\n",
    "                    # Plot the metrics.\n",
    "                    fig = plt.figure()\n",
    "                    fig.set_size_inches(num_subplots*10, 8)\n",
    "                    for i0, (k0, v0) in enumerate(six.iteritems(metrics_vals)):\n",
    "                        \n",
    "                        ax = fig.add_subplot(1, num_subplots, i0+1)\n",
    "                        ax.set_title(k0)\n",
    "                        for i1, (k1, v1) in enumerate(six.iteritems(v0)):\n",
    "                            for i2, (k2, v2) in enumerate(six.iteritems(v1)):\n",
    "                                ax.plot(iterations, v2, label='%s %s' % (k1, k2),\n",
    "                                        color=colors[i1], linestyle=styles[i2])\n",
    "                        ax.set_xlim([1, num_iterations])\n",
    "                        ax.set_yscale('log')\n",
    "                        ax.legend()\n",
    "                    # Plot the embeddings (first 3 dimensions).\n",
    "                    ax.legend(loc='upper right')\n",
    "                    ax = fig.add_subplot(1, num_subplots, num_subplots)\n",
    "                    ax.scatter(\n",
    "                        self._embeddings[:, 0], self._embeddings[:, 1],\n",
    "                        alpha=0.5, marker='o')\n",
    "                    ax.set_title('embeddings')\n",
    "\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        return self._embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cosmetic-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ build model\n",
      "------ train model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SimilarityModel' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-b1575d193369>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'------ train model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m similarity_model.train(\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SimilarityModel' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "#@title Training a DNN Similarity Model\n",
    "\n",
    "# Define some constants related to this dataset.\n",
    "sparse_feature_names = ('maker', 'maker_location', 'broad_origin',\n",
    "                        'specific_origin', 'bean_type')\n",
    "dense_feature_names = ('reference_number', 'review_date', 'cocoa_percent',\n",
    "                       'rating')\n",
    "\n",
    "# Set of features used as input to the similarity model.\n",
    "input_feature_names = ('maker', 'maker_location', 'broad_origin',\n",
    "                       'cocoa_percent', 'bean_type','rating', )\n",
    "# Set of features used as output to the similarity model.\n",
    "output_feature_names = ['rating']  #@param\n",
    "\n",
    "# As a rule of thumb, a reasonable choice for the embedding dimension of a\n",
    "# sparse feature column is the log2 of the cardinality of its vocabulary.\n",
    "# sparse_input_feature_embedding_dims = { 'maker': 9, 'maker_location': 6, ... }\n",
    "default_embedding_dims = {\n",
    "    sfn: int(round(math.log(choc_data[sfn].nunique()) / math.log(2)))\n",
    "    for sfn in set(sparse_feature_names).intersection(input_feature_names)\n",
    "}\n",
    "# Dictionary mapping each sparse input feature to the dimension of its embedding\n",
    "# space.\n",
    "sparse_input_feature_embedding_dims = default_embedding_dims  # can be a param\n",
    "\n",
    "# Weight of the L2 regularization applied to the top embedding layer.\n",
    "l2_regularization = 10  #@param\n",
    "# List of dimensions of the hidden layers of the deep neural network.\n",
    "hidden_dims = [20, 10]  #@param\n",
    "\n",
    "print('------ build model')\n",
    "with tf.Graph().as_default():\n",
    "    similarity_model = SimilarityModel(\n",
    "        choc_data,\n",
    "        input_feature_names=input_feature_names,\n",
    "        output_feature_names=output_feature_names,\n",
    "        dense_feature_names=dense_feature_names,\n",
    "        sparse_input_feature_embedding_dims=sparse_input_feature_embedding_dims,\n",
    "        hidden_dims=hidden_dims,\n",
    "        l2_regularization=l2_regularization,\n",
    "        batch_size=100,\n",
    "        use_bias=True,\n",
    "        inspect=True)\n",
    "\n",
    "print('------ train model')\n",
    "similarity_model.train(\n",
    "    num_iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    optimizer=tf.train.AdagradOptimizer)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-sullivan",
   "metadata": {},
   "source": [
    "# 4. Cluster Chocolate Dataset\n",
    "We're ready to cluster the chocolates! Run the code to set up the k-means clustering functions. You do not need to understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfSimilarity(df, centroids):\n",
    "    numPoints = len(df.index)\n",
    "    numCentroids = len(controids.index)\n",
    "    \n",
    "    pointNorms = np.square(nla.norm(df, axis=1))\n",
    "    pointNorms = np.reshape(pointNorms,[numPoints,1])\n",
    "    \n",
    "    centroidNorms = np.square(nla.norm(centroids,axis=1))\n",
    "    centroidNorms = np.reshape(centroidNorms,(1,numCentroids))\n",
    "    \n",
    "    similarities = pointNorms + centroidNorms - 2.0*np.dot(df,np.transpose(centroids))\n",
    "    \n",
    "    # Divide by the number of features\n",
    "    # Which is 10 because the one-hot encoding means the \"Maker\" and \"Bean\" are\n",
    "    # weighted twice\n",
    "    similarities = similarities/10.0\n",
    "    similarities = similarities.clip(min=0.0)\n",
    "    similarities = np.sqrt(similarities)\n",
    "    return similarities\n",
    "\n",
    "def initCentroids(df,k,feature_cols):\n",
    "    # Pick 'k' examples are random to serve as initial centroids\n",
    "    limit = len(df.index)\n",
    "    centroids_key = np.random.randint(0,limit-1,k)\n",
    "    centroids = df.loc[centroids_key,feature_cols].copy(deep=True)\n",
    "    # the indexes get copied over so reset them\n",
    "    centroids.reset_index(drop=True,inplace=True)\n",
    "    return centroids\n",
    "    \n",
    "def pt2centroid(df,centroids,feature_cols):\n",
    "    ### Calculate similarities between all points and centroids\n",
    "    ### And assign points to the closest centroid + save that distance\n",
    "    numCentroids = len(centroids.index)\n",
    "    numExamples = len(df.index)\n",
    "    # dfSimilarity = Calculate similarities for dataframe input\n",
    "    dist = dfSimilarity(df.loc[:,feature_cols],centroids.loc[:,feature_cols])\n",
    "    df.loc[:,'centroid'] = np.argmin(dist,axis=1) # closest centroid\n",
    "    df.loc[:,'pt2centroid'] = np.min(dist,axis=1) # minimum distance\n",
    "    return df\n",
    "\n",
    "def recomputeCentroids(df,centroids,feature_cols):\n",
    "    \n",
    "    ### For every centroid, recompute it as an average of the points\n",
    "    ### assigned to it\n",
    "    numCentroids = len(centroids.index)\n",
    "    for cen in range(numCentroids):\n",
    "        dfSubset = df.loc[df['centroid'] == cen, feature_cols] # all points for centroid\n",
    "        if not(dfSubset.empty): # if there are points assigned to the centroid\n",
    "            clusterAvg = np.sum(dfSubset)/len(dfSubset.index)\n",
    "            centroids.loc[cen] = clusterAvg\n",
    "    return centroids\n",
    "\n",
    "def kmeans(df,k,feature_cols,verbose):\n",
    "    flagConvergence = False\n",
    "    maxIter = 100\n",
    "    iter = 0                      # ensure kmeans doesn't run for ever\n",
    "    centroids = initCentroids(df,k,feature_cols)\n",
    "    while not(flagConvergence):\n",
    "        iter += 1\n",
    "        #Save old mapping of points to centroids\n",
    "        oldMapping = df['centroid'].copy(deep=True)\n",
    "        # Perform k-means\n",
    "        df = pt2centroid(df,centroids,feature_cols)\n",
    "        centroids = recomputeCentroids(df,centroids,feature_cols)\n",
    "        # Check convergence by comparing [oldMapping, newMapping]\n",
    "        newMapping = df['centroid']\n",
    "        flagConvergence = all(oldMapping == newMapping)\n",
    "        if verbose == 1:\n",
    "            print(\"Total distance:\" + str(np.sum(df['pt2centroid'])))\n",
    "        if (iter > maxIter):\n",
    "            print('k-means did not converge! Reached maximum iteration limit of ' \\\n",
    "                  + str(maxIter) + '.')\n",
    "            sys.exit()\n",
    "            return\n",
    "    \n",
    "    print('k-means converged for ' + str(k) + ' clusters' + \\\n",
    "          ' after ' + str(iter) + ' iterations!')\n",
    "    return [df,centroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 160 #@param\n",
    "\n",
    "# Extract embeddings into a dataframe\n",
    "choc_embed = similarity_model.embeddings\n",
    "choc_embed = pd.DataFrame(choc_embed)\n",
    "\n",
    "feature_cols = choc_embed.columns.values # save original columns\n",
    "# initialize every point to an impossible value, the k+1 cluster\n",
    "choc_embed['centroid'] = k\n",
    "# init the point to centroid distance to an impossible value \"2\" (>1)\n",
    "choc_embed['pt2centroid'] = 2\n",
    "[choc_embed,centroids] = kmeans(choc_embed,k,feature_cols,1)\n",
    "print(\"Data for the first few chocolates, with 'centroid' and 'pt2centroid' on the extreme right:\")\n",
    "choc_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-portrait",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
