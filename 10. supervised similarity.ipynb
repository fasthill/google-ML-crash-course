{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e508a54",
   "metadata": {},
   "source": [
    "# 1. Load and clean data\n",
    "Run the section below to load and clean the dataset. You do not need to understand the code. The code displays data for the first few chocolates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52151664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to load and clean the dataset\n",
    "%reset -f\n",
    "# from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg as nla\n",
    "import pandas as pd\n",
    "import re\n",
    "# import six\n",
    "# from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "febb1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output display to have one digit for decimal places and limit it to\n",
    "# printing 15 rows.\n",
    "pd.options.display.max_rows =  15\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be2c574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/flavors_of_cacao.csv\", sep=\",\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e5e29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns.\n",
    "choc_data.columns = ['maker', 'specific_origin', 'reference_number', 'review_date', 'cocoa_percent', 'maker_location', 'rating', 'bean_type', 'broad_origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bfaa419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maker                object\n",
       "specific_origin      object\n",
       "reference_number      int64\n",
       "review_date           int64\n",
       "cocoa_percent        object\n",
       "maker_location       object\n",
       "rating              float64\n",
       "bean_type            object\n",
       "broad_origin         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52188d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   maker             1795 non-null   object \n",
      " 1   specific_origin   1795 non-null   object \n",
      " 2   reference_number  1795 non-null   int64  \n",
      " 3   review_date       1795 non-null   int64  \n",
      " 4   cocoa_percent     1795 non-null   object \n",
      " 5   maker_location    1795 non-null   object \n",
      " 6   rating            1795 non-null   float64\n",
      " 7   bean_type         907 non-null    object \n",
      " 8   broad_origin      1721 non-null   object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 126.3+ KB\n"
     ]
    }
   ],
   "source": [
    "choc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "896caf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty/null values with \"Blend\"\n",
    "choc_data['bean_type'] = choc_data['bean_type'].fillna('Blend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74ef7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast bean_type to string to remove leading 'u'\n",
    "choc_data['bean_type'] = choc_data['bean_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c15940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data['cocoa_percent'] = choc_data['cocoa_percent'].str.strip('%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c26634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data['cocoa_percent'] = pd.to_numeric(choc_data['cocoa_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5980c1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   maker             1795 non-null   object \n",
      " 1   specific_origin   1795 non-null   object \n",
      " 2   reference_number  1795 non-null   int64  \n",
      " 3   review_date       1795 non-null   int64  \n",
      " 4   cocoa_percent     1795 non-null   float64\n",
      " 5   maker_location    1795 non-null   object \n",
      " 6   rating            1795 non-null   float64\n",
      " 7   bean_type         1795 non-null   object \n",
      " 8   broad_origin      1721 non-null   object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 126.3+ KB\n"
     ]
    }
   ],
   "source": [
    "choc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "general-lesson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Cibao Valley, Domin. Rep.</td>\n",
       "      <td>1061</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Domin. Rep.</td>\n",
       "      <td>1069</td>\n",
       "      <td>2013</td>\n",
       "      <td>82.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Domin. Rep.</td>\n",
       "      <td>1069</td>\n",
       "      <td>2013</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Kah Kow</td>\n",
       "      <td>Rizek Cacao, Domin. Rep.</td>\n",
       "      <td>1073</td>\n",
       "      <td>2013</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Xocolat</td>\n",
       "      <td>Hispaniola</td>\n",
       "      <td>1057</td>\n",
       "      <td>2013</td>\n",
       "      <td>66.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        maker                         specific_origin  reference_number  \\\n",
       "883   Kah Kow  Rizek Cacao, Cibao Valley, Domin. Rep.              1061   \n",
       "884   Kah Kow                Rizek Cacao, Domin. Rep.              1069   \n",
       "885   Kah Kow                Rizek Cacao, Domin. Rep.              1069   \n",
       "886   Kah Kow                Rizek Cacao, Domin. Rep.              1073   \n",
       "1758  Xocolat                              Hispaniola              1057   \n",
       "\n",
       "      review_date  cocoa_percent     maker_location  rating bean_type  \\\n",
       "883          2013          70.00  Domincan Republic    3.50     Blend   \n",
       "884          2013          82.00  Domincan Republic    3.00     Blend   \n",
       "885          2013          55.00  Domincan Republic    3.25     Blend   \n",
       "886          2013          62.00  Domincan Republic    3.25     Blend   \n",
       "1758         2013          66.00  Domincan Republic    3.00     Blend   \n",
       "\n",
       "            broad_origin  \n",
       "883   Dominican Republic  \n",
       "884   Dominican Republic  \n",
       "885   Dominican Republic  \n",
       "886   Dominican Republic  \n",
       "1758  Dominican Republic  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['maker_location'].isin(['Domincan Republic'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "coastal-baking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Trinidad, Heritage, Limited ed.</td>\n",
       "      <td>1193</td>\n",
       "      <td>2013</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Trinidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Colombia, Casa Luker</td>\n",
       "      <td>947</td>\n",
       "      <td>2012</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>729</td>\n",
       "      <td>2011</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Haiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Panama</td>\n",
       "      <td>745</td>\n",
       "      <td>2011</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Panama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>486</td>\n",
       "      <td>2010</td>\n",
       "      <td>100.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>Hacienda Las Trincheras</td>\n",
       "      <td>593</td>\n",
       "      <td>2010</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>Java</td>\n",
       "      <td>593</td>\n",
       "      <td>2010</td>\n",
       "      <td>69.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>San Martin</td>\n",
       "      <td>457</td>\n",
       "      <td>2009</td>\n",
       "      <td>70.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>Rio Caribe</td>\n",
       "      <td>457</td>\n",
       "      <td>2009</td>\n",
       "      <td>72.00</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Xocolat</td>\n",
       "      <td>Hispaniola</td>\n",
       "      <td>1057</td>\n",
       "      <td>2013</td>\n",
       "      <td>66.00</td>\n",
       "      <td>Domincan Republic</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    maker                  specific_origin  reference_number  \\\n",
       "121   Artisan du Chocolat  Trinidad, Heritage, Limited ed.              1193   \n",
       "122   Artisan du Chocolat             Colombia, Casa Luker               947   \n",
       "123   Artisan du Chocolat                            Haiti               729   \n",
       "124   Artisan du Chocolat                           Panama               745   \n",
       "125   Artisan du Chocolat                        Venezuela               486   \n",
       "...                   ...                              ...               ...   \n",
       "1743       Willie's Cacao          Hacienda Las Trincheras               593   \n",
       "1744       Willie's Cacao                             Java               593   \n",
       "1745       Willie's Cacao                       San Martin               457   \n",
       "1746       Willie's Cacao                       Rio Caribe               457   \n",
       "1758              Xocolat                       Hispaniola              1057   \n",
       "\n",
       "      review_date  cocoa_percent     maker_location  rating   bean_type  \\\n",
       "121          2013          72.00               U.K.    3.25  Trinitario   \n",
       "122          2012          72.00               U.K.    3.75       Blend   \n",
       "123          2011          72.00               U.K.    4.00       Blend   \n",
       "124          2011          72.00               U.K.    2.75       Blend   \n",
       "125          2010         100.00               U.K.    1.75       Blend   \n",
       "...           ...            ...                ...     ...         ...   \n",
       "1743         2010          72.00               U.K.    3.50       Blend   \n",
       "1744         2010          69.00               U.K.    3.75       Blend   \n",
       "1745         2009          70.00               U.K.    3.00       Blend   \n",
       "1746         2009          72.00               U.K.    3.25  Trinitario   \n",
       "1758         2013          66.00  Domincan Republic    3.00       Blend   \n",
       "\n",
       "            broad_origin  \n",
       "121             Trinidad  \n",
       "122             Colombia  \n",
       "123                Haiti  \n",
       "124               Panama  \n",
       "125            Venezuela  \n",
       "...                  ...  \n",
       "1743           Venezuela  \n",
       "1744           Indonesia  \n",
       "1745                Peru  \n",
       "1746           Venezuela  \n",
       "1758  Dominican Republic  \n",
       "\n",
       "[106 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['maker_location'].isin(['Domincan Republic','Amsterdam', 'U.K.', 'Niacragua'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76143337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling mistakes, and replace city with country name\n",
    "choc_data['maker_location'] = choc_data['maker_location']\\\n",
    ".str.replace('Amsterdam', 'Holland', regex=True)\\\n",
    ".str.replace('U.K.', 'England', regex=True)\\\n",
    ".str.replace('Niacragua', 'Nicaragua', regex=True)\\\n",
    ".str.replace('Domincan Republic', 'Dominican Republic', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aquatic-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding this so that Holland and Netherlands map to the same country.\n",
    "choc_data['maker_location'] = choc_data['maker_location']\\\n",
    ".str.replace('Holland', 'Netherlands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "single-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_spelling_abbrev(text):\n",
    "    replacements = [\n",
    "        ['-', ', '], ['/ ', ', '], ['/', ', '], ['\\(', ', '], [' and', ', '], [' &', ', '], ['\\)', ''],\n",
    "        ['Dom Rep|DR|Domin Rep|Dominican Rep,|Domincan Republic', 'Dominican Republic'],\n",
    "        ['Mad,|Mad$', 'Madagascar, '],\n",
    "        ['PNG', 'Papua New Guinea, '],\n",
    "        ['Guat,|Guat$', 'Guatemala, '],\n",
    "        ['Ven,|Ven$|Venez,|Venez$', 'Venezuela, '],\n",
    "        ['Ecu,|Ecu$|Ecuad,|Ecuad$', 'Ecuador, '],\n",
    "        ['Nic,|Nic$', 'Nicaragua, '],\n",
    "        ['Cost Rica', 'Costa Rica'],\n",
    "        ['Mex,|Mex$', 'Mexico, '],\n",
    "        ['Jam,|Jam$', 'Jamaica, '],\n",
    "        ['Haw,|Haw$', 'Hawaii, '],\n",
    "        ['Gre,|Gre$', 'Grenada, '],\n",
    "        ['Tri,|Tri$', 'Trinidad, '],\n",
    "        ['C Am', 'Central America'],\n",
    "        ['S America', 'South America'],\n",
    "        [', $', ''], [',  ', ', '], [', ,', ', '], ['\\xa0', ' '],[',\\s+', ','],\n",
    "        [' Bali', ',Bali']\n",
    "    ]\n",
    "    for i, j in replacements:\n",
    "        text = re.sub(i, j, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "decimal-guarantee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Akesson's (Pralus)</td>\n",
       "      <td>Madagascar, Ambolikapiky P.</td>\n",
       "      <td>502</td>\n",
       "      <td>2010</td>\n",
       "      <td>75.00</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Criollo</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Akesson's (Pralus)</td>\n",
       "      <td>Monte Alegre, D. Badero</td>\n",
       "      <td>508</td>\n",
       "      <td>2010</td>\n",
       "      <td>75.00</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>AMMA</td>\n",
       "      <td>Monte Alegre, 3 diff. plantations</td>\n",
       "      <td>572</td>\n",
       "      <td>2010</td>\n",
       "      <td>85.00</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Forastero (Parazinho)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>AMMA</td>\n",
       "      <td>Monte Alegre, 3 diff. plantations</td>\n",
       "      <td>572</td>\n",
       "      <td>2010</td>\n",
       "      <td>50.00</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Forastero (Parazinho)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>AMMA</td>\n",
       "      <td>Monte Alegre, 3 diff. plantations</td>\n",
       "      <td>572</td>\n",
       "      <td>2010</td>\n",
       "      <td>75.00</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Forastero (Parazinho)</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Valrhona</td>\n",
       "      <td>Sambirano, Ampamakia 2005, Millot P.</td>\n",
       "      <td>75</td>\n",
       "      <td>2006</td>\n",
       "      <td>64.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Wm</td>\n",
       "      <td>Guasare, Zulia Prov., 2015, batch 124</td>\n",
       "      <td>1912</td>\n",
       "      <td>2016</td>\n",
       "      <td>74.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Criollo</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Woodblock</td>\n",
       "      <td>Camino Verde P., Balao, Guayas</td>\n",
       "      <td>1042</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Ecuador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Zart Pralinen</td>\n",
       "      <td>Millot P., Ambanja</td>\n",
       "      <td>1820</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Criollo, Trinitario</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Loma Los Pinos, Yacao region, D.R.</td>\n",
       "      <td>875</td>\n",
       "      <td>2012</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   maker                        specific_origin  \\\n",
       "33    Akesson's (Pralus)            Madagascar, Ambolikapiky P.   \n",
       "34    Akesson's (Pralus)                Monte Alegre, D. Badero   \n",
       "89                  AMMA      Monte Alegre, 3 diff. plantations   \n",
       "90                  AMMA      Monte Alegre, 3 diff. plantations   \n",
       "91                  AMMA      Monte Alegre, 3 diff. plantations   \n",
       "...                  ...                                    ...   \n",
       "1702            Valrhona   Sambirano, Ampamakia 2005, Millot P.   \n",
       "1747                  Wm  Guasare, Zulia Prov., 2015, batch 124   \n",
       "1751           Woodblock         Camino Verde P., Balao, Guayas   \n",
       "1767       Zart Pralinen                     Millot P., Ambanja   \n",
       "1783              Zotter     Loma Los Pinos, Yacao region, D.R.   \n",
       "\n",
       "      reference_number  review_date  cocoa_percent maker_location  rating  \\\n",
       "33                 502         2010          75.00    Switzerland    2.75   \n",
       "34                 508         2010          75.00    Switzerland    2.75   \n",
       "89                 572         2010          85.00         Brazil    2.75   \n",
       "90                 572         2010          50.00         Brazil    3.75   \n",
       "91                 572         2010          75.00         Brazil    3.75   \n",
       "...                ...          ...            ...            ...     ...   \n",
       "1702                75         2006          64.00         France    3.50   \n",
       "1747              1912         2016          74.00         U.S.A.    3.00   \n",
       "1751              1042         2013          70.00         U.S.A.    3.25   \n",
       "1767              1820         2016          70.00        Austria    3.50   \n",
       "1783               875         2012          62.00        Austria    3.75   \n",
       "\n",
       "                  bean_type        broad_origin  \n",
       "33                  Criollo          Madagascar  \n",
       "34                Forastero              Brazil  \n",
       "89    Forastero (Parazinho)              Brazil  \n",
       "90    Forastero (Parazinho)              Brazil  \n",
       "91    Forastero (Parazinho)              Brazil  \n",
       "...                     ...                 ...  \n",
       "1702             Trinitario          Madagascar  \n",
       "1747                Criollo           Venezuela  \n",
       "1751                  Blend             Ecuador  \n",
       "1767    Criollo, Trinitario          Madagascar  \n",
       "1783                  Blend  Dominican Republic  \n",
       "\n",
       "[156 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['specific_origin'].str.contains('\\.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "understanding-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "choc_data['specific_origin'] = choc_data['specific_origin']\\\n",
    ".str.replace('\\.', '', regex=True).apply(cleanup_spelling_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ongoing-confidentiality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loma Los Pinos,Yacao region,Dominican Republic'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data['specific_origin'][1783]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "trying-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   maker             1795 non-null   object \n",
      " 1   specific_origin   1795 non-null   object \n",
      " 2   reference_number  1795 non-null   int64  \n",
      " 3   review_date       1795 non-null   int64  \n",
      " 4   cocoa_percent     1795 non-null   float64\n",
      " 5   maker_location    1795 non-null   object \n",
      " 6   rating            1795 non-null   float64\n",
      " 7   bean_type         1795 non-null   object \n",
      " 8   broad_origin      1721 non-null   object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 126.3+ KB\n"
     ]
    }
   ],
   "source": [
    "choc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ethical-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast specific_origin to string\n",
    "choc_data['specific_origin'] = choc_data['specific_origin'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "maritime-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null-valued fields with the same value as for specific_origin\n",
    "choc_data['broad_origin'] = choc_data['broad_origin'].fillna(choc_data['specific_origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "medical-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up spelling mistakes and deal with abbreviations\n",
    "choc_data['broad_origin'] = choc_data['broad_origin'].str.replace('\\.', '', regex=True).apply(cleanup_spelling_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "minor-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Cacao Barry</td>\n",
       "      <td>Grand 'Anse</td>\n",
       "      <td>1716</td>\n",
       "      <td>2016</td>\n",
       "      <td>65.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Haiti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>Felchlin</td>\n",
       "      <td>Elvesia P</td>\n",
       "      <td>105</td>\n",
       "      <td>2006</td>\n",
       "      <td>74.00</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>Guittard</td>\n",
       "      <td>Sur del Lago</td>\n",
       "      <td>87</td>\n",
       "      <td>2006</td>\n",
       "      <td>65.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Hotel Chocolat (Coppeneur)</td>\n",
       "      <td>Sambirano</td>\n",
       "      <td>809</td>\n",
       "      <td>2012</td>\n",
       "      <td>66.00</td>\n",
       "      <td>England</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>Hummingbird</td>\n",
       "      <td>Ocumare,Cumboto</td>\n",
       "      <td>1097</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>La Chocolaterie Nanairo</td>\n",
       "      <td>Lumas,2015 Harvest,Batch 6,brown sugar</td>\n",
       "      <td>1892</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2.25</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>La Chocolaterie Nanairo</td>\n",
       "      <td>Lumas,2015 Harvest,Batch 7</td>\n",
       "      <td>1892</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>La Chocolaterie Nanairo</td>\n",
       "      <td>Belize,2014 Harvest,Batch 9</td>\n",
       "      <td>1892</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Belize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>Scharffen Berger</td>\n",
       "      <td>Amina</td>\n",
       "      <td>464</td>\n",
       "      <td>2010</td>\n",
       "      <td>65.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Trinitario, Criollo</td>\n",
       "      <td>Madagascar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           maker                         specific_origin  \\\n",
       "284                  Cacao Barry                             Grand 'Anse   \n",
       "645                     Felchlin                               Elvesia P   \n",
       "766                     Guittard                            Sur del Lago   \n",
       "837   Hotel Chocolat (Coppeneur)                               Sambirano   \n",
       "854                  Hummingbird                         Ocumare,Cumboto   \n",
       "926      La Chocolaterie Nanairo  Lumas,2015 Harvest,Batch 6,brown sugar   \n",
       "927      La Chocolaterie Nanairo              Lumas,2015 Harvest,Batch 7   \n",
       "929      La Chocolaterie Nanairo             Belize,2014 Harvest,Batch 9   \n",
       "1430            Scharffen Berger                                   Amina   \n",
       "\n",
       "      reference_number  review_date  cocoa_percent maker_location  rating  \\\n",
       "284               1716         2016          65.00         France    3.50   \n",
       "645                105         2006          74.00    Switzerland    3.00   \n",
       "766                 87         2006          65.00         U.S.A.    2.50   \n",
       "837                809         2012          66.00        England    3.50   \n",
       "854               1097         2013          70.00         Canada    3.25   \n",
       "926               1892         2016          70.00          Japan    2.25   \n",
       "927               1892         2016          70.00          Japan    2.50   \n",
       "929               1892         2016          70.00          Japan    3.00   \n",
       "1430               464         2010          65.00         U.S.A.    3.75   \n",
       "\n",
       "                bean_type        broad_origin  \n",
       "284   Trinitario, Criollo               Haiti  \n",
       "645   Trinitario, Criollo  Dominican Republic  \n",
       "766   Trinitario, Criollo           Venezuela  \n",
       "837   Trinitario, Criollo          Madagascar  \n",
       "854   Trinitario, Criollo           Venezuela  \n",
       "926   Trinitario, Criollo                Peru  \n",
       "927   Trinitario, Criollo                Peru  \n",
       "929   Trinitario, Criollo              Belize  \n",
       "1430  Trinitario, Criollo          Madagascar  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['bean_type'].isin(['Trinitario, Criollo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "heated-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blend', 'Criollo', 'Trinitario', 'Forastero (Arriba)',\n",
       "       'Forastero', 'Forastero (Nacional)', 'Criollo, Trinitario',\n",
       "       'Criollo (Porcelana)', 'Trinitario (85% Criollo)',\n",
       "       'Forastero (Catongo)', 'Forastero (Parazinho)',\n",
       "       'Trinitario, Criollo', 'CCN51', 'Criollo (Ocumare)', 'Nacional',\n",
       "       'Criollo (Ocumare 61)', 'Criollo (Ocumare 77)',\n",
       "       'Criollo (Ocumare 67)', 'Criollo (Wild)', 'Beniano', 'Amazon mix',\n",
       "       'Trinitario, Forastero', 'Forastero (Arriba) ASS', 'Criollo, +',\n",
       "       'Amazon', 'Amazon, ICS', 'EET', 'Blend-Forastero,Criollo',\n",
       "       'Trinitario (Scavina)', 'Criollo, Forastero', 'Matina',\n",
       "       'Forastero(Arriba, CCN)', 'Nacional (Arriba)',\n",
       "       'Forastero (Arriba) ASSS', 'Forastero, Trinitario',\n",
       "       'Forastero (Amelonado)', 'Trinitario, Nacional',\n",
       "       'Trinitario (Amelonado)', 'Trinitario, TCGA', 'Criollo (Amarru)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data['bean_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "talented-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blend                   929\n",
       "Trinitario              419\n",
       "Criollo                 153\n",
       "Forastero                87\n",
       "Forastero (Nacional)     52\n",
       "                       ... \n",
       "Criollo (Ocumare)         1\n",
       "Amazon                    1\n",
       "Criollo, +                1\n",
       "Criollo (Ocumare 77)      1\n",
       "CCN51                     1\n",
       "Name: bean_type, Length: 40, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data['bean_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "configured-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'Trinitario, Criollo' to \"Criollo, Trinitario\"\n",
    "# Check with choc_data['bean_type'].unique()\n",
    "choc_data.loc[choc_data['bean_type'].isin(['Trinitario, Criollo']),'bean_type'] = \"Criollo, Trinitario\"\n",
    "# Confirm with choc_data[choc_data['bean_type'].isin(['Trinitario, Criollo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "mathematical-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>Naive</td>\n",
       "      <td>Trinidad,Tobago</td>\n",
       "      <td>1046</td>\n",
       "      <td>2013</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Trinidad,Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>Naive</td>\n",
       "      <td>Maranon Canyon,Fortunato No 4</td>\n",
       "      <td>1133</td>\n",
       "      <td>2013</td>\n",
       "      <td>78.00</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Forastero (Nacional)</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>Naive</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>867</td>\n",
       "      <td>2012</td>\n",
       "      <td>71.00</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Grenada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker                specific_origin  reference_number  review_date  \\\n",
       "1162  Naive                Trinidad,Tobago              1046         2013   \n",
       "1163  Naive  Maranon Canyon,Fortunato No 4              1133         2013   \n",
       "1164  Naive                        Grenada               867         2012   \n",
       "\n",
       "      cocoa_percent maker_location  rating             bean_type  \\\n",
       "1162          70.00      Lithuania    3.75                 Blend   \n",
       "1163          78.00      Lithuania    3.75  Forastero (Nacional)   \n",
       "1164          71.00      Lithuania    2.50            Trinitario   \n",
       "\n",
       "         broad_origin  \n",
       "1162  Trinidad,Tobago  \n",
       "1163             Peru  \n",
       "1164          Grenada  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data[choc_data['maker'].str.contains(r'Na\\w*ve')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "concerned-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix chocolate maker names\n",
    "choc_data.loc[choc_data['maker']=='Shattel','maker'] = 'Shattell'\n",
    "choc_data['maker'] = choc_data['maker'].str.replace(u'Na\\xef\\xbf\\xbdve','Naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-governor",
   "metadata": {},
   "source": [
    "The u in <span style='color:red'>u'Some String'</span> means that your string is a <span style='color:red'>Unicode string</span>.\n",
    "<span style='color:blue'>In Python 3.x the strings use Unicode by default</span> and there's no need for the u prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "superb-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker specific_origin  reference_number  review_date  cocoa_percent  \\\n",
       "0  A. Morin     Agua Grande              1876         2016          63.00   \n",
       "1  A. Morin           Kpime              1676         2015          70.00   \n",
       "2  A. Morin          Atsane              1676         2015          70.00   \n",
       "3  A. Morin           Akata              1680         2015          70.00   \n",
       "4  A. Morin          Quilla              1704         2015          70.00   \n",
       "\n",
       "  maker_location  rating bean_type broad_origin  \n",
       "0         France    3.75     Blend     Sao Tome  \n",
       "1         France    2.75     Blend         Togo  \n",
       "2         France    3.00     Blend         Togo  \n",
       "3         France    3.50     Blend         Togo  \n",
       "4         France    3.50     Blend         Peru  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-calculation",
   "metadata": {},
   "source": [
    "# 2. Process Data\n",
    "Because you're using a DNN, you do not need to manually process the data. The DNN transforms the data for us. However, if possible, you should remove features that could distort the similarity calculation. Here, the features `review_date` and `reference_number` are not correlated with similarity. That is, chocolates that are reviewed closer together in time are not more or less similar than chocolates reviewed further apart. Remove these two features by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "generic-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker specific_origin  cocoa_percent maker_location  rating bean_type  \\\n",
       "0  A. Morin     Agua Grande          63.00         France    3.75     Blend   \n",
       "1  A. Morin           Kpime          70.00         France    2.75     Blend   \n",
       "2  A. Morin          Atsane          70.00         France    3.00     Blend   \n",
       "3  A. Morin           Akata          70.00         France    3.50     Blend   \n",
       "4  A. Morin          Quilla          70.00         France    3.50     Blend   \n",
       "\n",
       "  broad_origin  \n",
       "0     Sao Tome  \n",
       "1         Togo  \n",
       "2         Togo  \n",
       "3         Togo  \n",
       "4         Peru  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data.drop(columns=['review_date','reference_number'],inplace=True)\n",
    "choc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-forward",
   "metadata": {},
   "source": [
    "# 3. Generate Embeddings from DNN\n",
    "\n",
    "We're ready to generate embeddings by training the DNN on the feature data. This section draws on concepts discussed on the page [Supervised Similarity Measure](https://developers.google.com/machine-learning/clustering/similarity/supervised-similarity).\n",
    "\n",
    "Run the section below to set up functions to train the DNN that generates embeddings. You do not need to understand the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-monkey",
   "metadata": {},
   "source": [
    "### Functions to Build and Train a Similarity DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "proprietary-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityModel(object):\n",
    "    \n",
    "    \"\"\"Class to build, train, and inspect a Similarity Model.\n",
    "\n",
    "      This class builds a deep neural network that maps a dataset of entities\n",
    "      with heterogenous features to an embedding space.\n",
    "      Given a dataset as a pandas dataframe, determine the model by specifying\n",
    "      the set of features used as input and as labels to the DNN, and the\n",
    "      size of each hidden layer. The data is mapped to the embedding space\n",
    "      in the last hidden layer.\n",
    "\n",
    "      To build an auto-encoder, make the set of output features identical to the set\n",
    "      of input features. Alternatively, build a predictor by using a single feature\n",
    "      as the label. When using a single feature as a label, ensure\n",
    "      this feature is removed from the input, or add at least\n",
    "      one hidden layer of a sufficiently low dimension such that the model cannot\n",
    "      trivially learn the label.\n",
    "      Caveat: The total loss being minimized is a simple sum of losses for each\n",
    "        output label (plus the regularization). If the output feature set combines\n",
    "        sparse and dense features, the total loss is a sum of cross-entropy soft-max\n",
    "        losses with root mean squared error losses, potentially in different scales,\n",
    "        which could emphasis some output labels more than others.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dataframe,\n",
    "                 input_feature_names,\n",
    "                 output_feature_names,\n",
    "                 dense_feature_names,\n",
    "                 sparse_input_feature_embedding_dims,\n",
    "                 hidden_dims=[32],\n",
    "                 l2_regularization=0.0,\n",
    "                 use_bias=True,\n",
    "                 batch_size=100,\n",
    "                 inspect=False):\n",
    "        \"\"\"Build a similarity model.\n",
    "\n",
    "        Args:\n",
    "          dataframe: the pandas dataframe used to train and validate the model.\n",
    "          input_feature_names: list of strings, names of input feature columns.\n",
    "          output_feature_names: list of strings, names of output feature columns.\n",
    "          dense_feature_names: list of strings, names of feature columns that are\n",
    "            treated as dense. All other feature columns are treated as sparse.\n",
    "          sparse_input_feature_embedding_dims: dictionary that maps feature names to\n",
    "            ints, expressing the embedding dimension of each input feature. Any\n",
    "            sparse feature in input_feature_names must be in this dictionary.\n",
    "          hidden_dims: list of ints, dimensions of each hidden layer. These hidden\n",
    "            layers are not counting the first layer which is a concatenation of the\n",
    "            input embeddings and the dense input features. Hence, this list can be\n",
    "            empty, in which case the outputs of the network are directly connected\n",
    "            to the input embeddings and/or dense inputs.\n",
    "          use_bias: bool, if true, add a bias term to each hidden layer.\n",
    "          batch_size: int, batch size.\n",
    "          inspect: bool, if true, add each tensor of the model to the list of\n",
    "            tensors that are inspected.\n",
    "          \"\"\"\n",
    "            \n",
    "        used_feature_names = tuple(\n",
    "            set(input_feature_names).union(output_feature_names))\n",
    "        sparse_feature_names = tuple(\n",
    "            set(used_feature_names).difference(dense_feature_names))\n",
    "        # Dictionary mapping each sparse feature column to its vocabulary.\n",
    "        ### sparse_feature_vocabs = { 'maker': [u'A. Morin', u'AMMA', ...], ... }\n",
    "        sparse_feature_vocabs = {\n",
    "            sfn: sorted(list(set(choc_data[sfn].values)))\n",
    "            for sfn in sparse_feature_names\n",
    "        }\n",
    "\n",
    "        # Sparse output features are mapped to ids via tf.feature_to_id, hence\n",
    "        # we need key-id pairs for these vocabularies.\n",
    "        sparse_output_feature_names = (\n",
    "            tuple(set(sparse_feature_names).intersection(output_feature_names)))\n",
    "        keys_and_values = {}\n",
    "        for fn in sparse_output_feature_names:\n",
    "            keys = tf.constant(\n",
    "                sparse_feature_vocabs[fn],\n",
    "                dtype=tf.string,\n",
    "                name='{}_vocab_keys'.format(fn))\n",
    "            values = tf.range(\n",
    "                len(sparse_feature_vocabs[fn]),\n",
    "                dtype=tf.int64,\n",
    "                name='{}_vocab_values'.format(fn))\n",
    "            keys_and_values[fn] = (keys, values)\n",
    "\n",
    "        # Class instance data members.\n",
    "        self._session = None\n",
    "        self._loss = None\n",
    "        self._metrics = {}\n",
    "        self._embeddings = None\n",
    "        self._vars_to_inspect = {}\n",
    "\n",
    "        def split_dataframe(df, holdout_fraction=0.1):\n",
    "            \"\"\"\n",
    "      Splits a pandas dataframe into training and test sets.\n",
    "\n",
    "      Args:\n",
    "        df: the source pandas dataframe.\n",
    "        holdout_fraction: fraction of dataframe rows to use in the test set.\n",
    "\n",
    "      Returns:\n",
    "        A pair of non-overlapping pandas dataframe for training and holdout.\n",
    "            \"\"\"\n",
    "        \n",
    "            test = df.sample(frac=holdout_fraction, replace=False)\n",
    "            train = df[~df.index.isin(test.index)]\n",
    "            return train, test\n",
    "\n",
    "        train_dataframe, test_dataframe = split_dataframe(dataframe)\n",
    "\n",
    "        def make_batch(dataframe, batch_size):\n",
    "            \"\"\"Creates a batch of examples.\n",
    "\n",
    "          Args:\n",
    "            dataframe: a panda dataframe with rows being examples and with\n",
    "              columns being feature columns.\n",
    "            batch_size: the batch size.\n",
    "\n",
    "          Returns:\n",
    "            A dictionary of tensors, keyed by their feature names.\n",
    "            Each tensor is of shape [batch_size]. Tensors for sparse features are of\n",
    "            strings, while tensors for dense features are of floats.\n",
    "            \"\"\"\n",
    "            used_features = {ufn: dataframe[ufn] for ufn in used_feature_names}\n",
    "            batch = (\n",
    "                tf.data.Dataset.from_tensor_slices(used_features).shuffle(1000)\n",
    "                .repeat().batch(batch_size).make_one_shot_iterator().get_next())\n",
    "            if inspect:\n",
    "                for k, v in six.iteritems(batch):\n",
    "                    self._vars_to_inspect['input_%s' % k] = v\n",
    "            return batch\n",
    "\n",
    "        def generate_feature_columns(feature_names):\n",
    "            \"\"\"Creates the list of used feature columns.\n",
    "\n",
    "          Args:\n",
    "            feature_names: an iterable of strings with the names of the features for\n",
    "              which feature columns are generated.\n",
    "\n",
    "          Returns:\n",
    "            A dictionary, keyed by feature names, of _DenseColumn and\n",
    "            _NumericColumn.\n",
    "            \"\"\"\n",
    "            used_sparse_feature_names = (\n",
    "                tuple(set(sparse_feature_names).intersection(feature_names)))\n",
    "            used_dense_feature_names = (\n",
    "                tuple(set(dense_feature_names).intersection(feature_names)))\n",
    "            f_columns = {}\n",
    "            for sfn in used_sparse_feature_names:\n",
    "                sf_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                    key=sfn,\n",
    "                    vocabulary_list=sparse_feature_vocabs[sfn],\n",
    "                    num_oov_buckets=0)\n",
    "                f_columns[sfn] = tf.feature_column.embedding_column(\n",
    "                    categorical_column=sf_column,\n",
    "                    dimension=sparse_input_feature_embedding_dims[sfn],\n",
    "                    combiner='mean',\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=.1))\n",
    "            for dfn in used_dense_feature_names:\n",
    "                f_columns[dfn] = tf.feature_column.numeric_column(dfn)\n",
    "            return f_columns\n",
    "\n",
    "        def create_tower(features, columns):\n",
    "            \"\"\"Creates the tower mapping features to embeddings.\n",
    "\n",
    "          Args:\n",
    "            features: a dictionary of tensors of shape [batch_size], keyed by\n",
    "              feature name. Sparse features are associated to tensors of strings,\n",
    "              while dense features are associated to tensors of floats.\n",
    "            columns: a dictionary, keyed by feature names, of _DenseColumn and\n",
    "              _NumericColumn.\n",
    "\n",
    "          Returns:\n",
    "            A pair of elements: hidden_layer and output_layer.\n",
    "              hidden_layer is a tensor of shape [batch_size, hidden_dims[-1]].\n",
    "              output_layer is a dictionary keyed by the output feature names, of\n",
    "                dictionaries {'labels': labels, 'logits': logits}.\n",
    "                Dense output features have both labels and logits as float tensors \n",
    "                of shape [batch_size, 1]. Sparse output features have labels as\n",
    "                string tensors of shape [batch_size, 1] and logits as float tensors\n",
    "                of shape [batch_size, len(sparse_feature_vocab)].\n",
    "            \"\"\"\n",
    "          # TODO: sanity check the arguments.\n",
    "          # Input features.\n",
    "            input_columns = [columns[fn] for fn in input_feature_names]\n",
    "            hidden_layer = tf.feature_column.input_layer(features, input_columns)\n",
    "            dense_input_feature_names = (\n",
    "                tuple(set(dense_feature_names).intersection(input_feature_names)))\n",
    "            input_dim = (\n",
    "                sum(sparse_input_feature_embedding_dims.values()) +\n",
    "                len(dense_input_feature_names))\n",
    "            for layer_idx, layer_output_dim in enumerate(hidden_dims):\n",
    "                w = tf.get_variable(\n",
    "                    'hidden%d_w_' % layer_idx,\n",
    "                    shape=[input_dim, layer_output_dim],\n",
    "                    initializer=tf.truncated_normal_initializer(\n",
    "                        stddev=1.0 / np.sqrt(layer_output_dim)))\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['hidden%d_w_' % layer_idx] = w\n",
    "                hidden_layer = tf.matmul(hidden_layer, w)  # / 10.)\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['hidden_layer_%d' % layer_idx] = hidden_layer\n",
    "                input_dim = layer_output_dim\n",
    "              # Output features.\n",
    "            output_layer = {}\n",
    "            for ofn in output_feature_names:\n",
    "                if ofn in sparse_feature_names:\n",
    "                    feature_dim = len(sparse_feature_vocabs[ofn])\n",
    "                else:\n",
    "                    feature_dim = 1\n",
    "                w = tf.get_variable(\n",
    "                    'output_w_%s' % ofn,\n",
    "                    shape=[input_dim, feature_dim],\n",
    "                    initializer=tf.truncated_normal_initializer(stddev=1.0 /\n",
    "                                                                np.sqrt(feature_dim)))\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['output_w_%s' % ofn] = w\n",
    "                if use_bias:\n",
    "                    bias = tf.get_variable(\n",
    "                        'output_bias_%s' % ofn,\n",
    "                        shape=[1, feature_dim],\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=1.0 /\n",
    "                                                                    np.sqrt(feature_dim)))\n",
    "                    if inspect:\n",
    "                        self._vars_to_inspect['output_bias_%s' % ofn] = bias\n",
    "                else:\n",
    "                    bias = tf.constant(0.0, shape=[1, feature_dim])\n",
    "                output_layer[ofn] = {\n",
    "                    'labels':\n",
    "                        features[ofn],\n",
    "                    'logits':\n",
    "                        tf.add(tf.matmul(hidden_layer, w), bias)  # w / 10.), bias)\n",
    "                }\n",
    "                if inspect:\n",
    "                    self._vars_to_inspect['output_labels_%s' %\n",
    "                                        ofn] = output_layer[ofn]['labels']\n",
    "                    self._vars_to_inspect['output_logits_%s' %\n",
    "                                        ofn] = output_layer[ofn]['logits']\n",
    "                return hidden_layer, output_layer\n",
    "\n",
    "        def similarity_loss(top_embeddings, output_layer):\n",
    "            \"\"\"Build the loss to be optimized.\n",
    "\n",
    "          Args:\n",
    "            top_embeddings: First element returned by create_tower.\n",
    "            output_layer: Second element returned by create_tower.\n",
    "\n",
    "          Returns:\n",
    "            total_loss: A tensor of shape [1] with the total loss to be optimized.\n",
    "            losses: A dictionary keyed by output feature names, of tensors of shape\n",
    "              [1] with the contribution to the loss of each output feature.\n",
    "            \"\"\"\n",
    "            losses = {}\n",
    "            total_loss = tf.scalar_mul(l2_regularization,\n",
    "                                        tf.nn.l2_loss(top_embeddings))\n",
    "            for fn, output in six.iteritems(output_layer):\n",
    "                if fn in sparse_feature_names:\n",
    "                    losses[fn] = tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                            logits=output['logits'],\n",
    "                            labels=tf.feature_to_id(\n",
    "                                output['labels'], keys_and_values=keys_and_values[fn])))\n",
    "                else:\n",
    "                    losses[fn] = tf.sqrt(\n",
    "                        tf.reduce_mean(\n",
    "                            tf.square(output['logits'] -\n",
    "                                    tf.cast(output['labels'], tf.float32))))\n",
    "                total_loss += losses[fn]\n",
    "                return total_loss, losses\n",
    "\n",
    "        # Body of the constructor.\n",
    "        input_feature_columns = generate_feature_columns(input_feature_names)\n",
    "        # Train\n",
    "        with tf.variable_scope('model', reuse=False):\n",
    "            train_hidden_layer, train_output_layer = create_tower(\n",
    "                make_batch(train_dataframe, batch_size), input_feature_columns)\n",
    "            self._train_loss, train_losses = similarity_loss(train_hidden_layer,\n",
    "                                                            train_output_layer)\n",
    "        # Test\n",
    "        with tf.variable_scope('model', reuse=True):\n",
    "            test_hidden_layer, test_output_layer = create_tower(\n",
    "                make_batch(test_dataframe, batch_size), input_feature_columns)\n",
    "            test_loss, test_losses = similarity_loss(test_hidden_layer,\n",
    "                                                    test_output_layer)\n",
    "        # Whole dataframe to get final embeddings\n",
    "        with tf.variable_scope('model', reuse=True):\n",
    "            self._hidden_layer, _ = create_tower(\n",
    "                make_batch(dataframe, dataframe.shape[0]), input_feature_columns)\n",
    "        # Metrics is a dictionary of dictionaries of dictionaries.\n",
    "        # The 3 levels are used as plots, line colors, and line styles respectively.\n",
    "        self._metrics = {\n",
    "            'total': {\n",
    "                'train': {'loss': self._train_loss},\n",
    "                'test': {'loss': test_loss}\n",
    "            },\n",
    "            'feature': {\n",
    "                'train': {'%s loss' % k: v for k, v in six.iteritems(train_losses)},\n",
    "                'test': {'%s loss' % k: v for k, v in six.iteritems(test_losses)}\n",
    "            }\n",
    "        }\n",
    "\n",
    "        def train(self,\n",
    "                  num_iterations=30,\n",
    "                  learning_rate=1.0,\n",
    "                  plot_results=True,\n",
    "                  optimizer=tf.train.GradientDescentOptimizer):\n",
    "            \"\"\"Trains the model.\n",
    "\n",
    "        Args:\n",
    "          num_iterations: int, the number of iterations to run.\n",
    "          learning_rate: float, the optimizer learning rate.\n",
    "          plot_results: bool, whether to plot the results at the end of training.\n",
    "          optimizer: tf.train.Optimizer, the optimizer to be used for training.\n",
    "            \"\"\"\n",
    "            with self._train_loss.graph.as_default():\n",
    "                opt = optimizer(learning_rate)\n",
    "                train_op = opt.minimize(self._train_loss)\n",
    "                opt_init_op = tf.variables_initializer(opt.variables())\n",
    "                if self._session is None:\n",
    "                    self._session = tf.Session()\n",
    "                    with self._session.as_default():\n",
    "                        self._session.run(tf.global_variables_initializer())\n",
    "                        self._session.run(tf.local_variables_initializer())\n",
    "                        self._session.run(tf.tables_initializer())\n",
    "                        tf.train.start_queue_runners()\n",
    "\n",
    "            with self._session.as_default():\n",
    "                self._session.run(opt_init_op)\n",
    "                if plot_results:  \n",
    "                    iterations = []\n",
    "                    metrics_vals = {k0: {k1: {k2: []\n",
    "                                              for k2 in v1}\n",
    "                                         for k1, v1 in six.iteritems(v0)}\n",
    "                                    for k0, v0 in six.iteritems(self._metrics)}\n",
    "\n",
    "                  # Train and append results.\n",
    "                for i in range(num_iterations + 1):\n",
    "                    _, results = self._session.run((train_op, self._metrics))\n",
    "\n",
    "                    # Printing the 1 liner with losses.\n",
    "                    if (i % 10 == 0) or i == num_iterations:\n",
    "                        print('\\riteration%6d,   ' % i + ',   '.join(\n",
    "                            ['%s %s %s: %7.3f' % (k0, k1, k2, v2)\n",
    "                            for k0, v0 in six.iteritems(results)\n",
    "                            for k1, v1 in six.iteritems(v0)\n",
    "                            for k2, v2 in six.iteritems(v1)])\n",
    "                            , end=\" \"\n",
    "                            )\n",
    "                        if plot_results:\n",
    "                            iterations.append(i)\n",
    "                            for k0, v0 in six.iteritems(results):\n",
    "                                for k1, v1 in six.iteritems(v0):\n",
    "                                    for k2, v2 in six.iteritems(v1):\n",
    "                                        metrics_vals[k0][k1][k2].append(results[k0][k1][k2])\n",
    "\n",
    "                # Feedforward the entire dataframe to get all the embeddings.\n",
    "                self._embeddings = self._session.run(self._hidden_layer)\n",
    "\n",
    "                # Plot the losses and embeddings.\n",
    "                if plot_results:\n",
    "                    num_subplots = len(metrics_vals) + 1\n",
    "                    colors = 10 * ('red', 'blue', 'black', 'green')\n",
    "                    styles = 10 * ('-', '--', '-.', ':')\n",
    "                    # Plot the metrics.\n",
    "                    fig = plt.figure()\n",
    "                    fig.set_size_inches(num_subplots*10, 8)\n",
    "                    for i0, (k0, v0) in enumerate(six.iteritems(metrics_vals)):\n",
    "                        \n",
    "                        ax = fig.add_subplot(1, num_subplots, i0+1)\n",
    "                        ax.set_title(k0)\n",
    "                        for i1, (k1, v1) in enumerate(six.iteritems(v0)):\n",
    "                            for i2, (k2, v2) in enumerate(six.iteritems(v1)):\n",
    "                                ax.plot(iterations, v2, label='%s %s' % (k1, k2),\n",
    "                                        color=colors[i1], linestyle=styles[i2])\n",
    "                        ax.set_xlim([1, num_iterations])\n",
    "                        ax.set_yscale('log')\n",
    "                        ax.legend()\n",
    "                    # Plot the embeddings (first 3 dimensions).\n",
    "                    ax.legend(loc='upper right')\n",
    "                    ax = fig.add_subplot(1, num_subplots, num_subplots)\n",
    "                    ax.scatter(\n",
    "                        self._embeddings[:, 0], self._embeddings[:, 1],\n",
    "                        alpha=0.5, marker='o')\n",
    "                    ax.set_title('embeddings')\n",
    "\n",
    "\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        return self._embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
